# -*- coding: utf-8 -*-
"""Scikit_learn_metrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VsdIVeqWVIrnqwxhUTT69c93KzIahKsS
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("creditcard_2023.csv")[:80_000] #this represents that i am reading  the first 80000 rows in data
df.head(3)

# to get this data into scikit-learn we have
X= df.drop(columns=['id', 'Amount', 'Class']).values
y= df['Class'].values
# to emphasise what kind of dataframe it is we have
f"Shape of x = {X.shape} y={y.shape}, #Fraud Cases={y.sum()}"

# so lets start with simple models like logistic regression
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(class_weight={0 : 1, 1: 2})
model.fit(X, y).predict(X).sum()
# model.get_params()
# model.score(X,y, sample_weight=None)

# now lets use grid search and get it
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_score, recall_score, make_scorer

# now we need to create a grid
grid = GridSearchCV(
    estimator=LogisticRegression(),
    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},
    scoring={'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)},
    refit='precision',
    return_train_score=True,
    cv=10,
    n_jobs = -1
)
grid.fit(X,y)

"""**We will use some scikit-learn metricmodel**"""

# from sklearn.metrics import precision_score, recall_score
# # precision_score(y,  grid.predict(X))
# recall_score(y, grid.predict(X))

pd.DataFrame(grid.cv_results_) #it has all the results from cross validation

plt.figure(figsize=(12, 4))
df = pd.DataFrame(grid.cv_results_)
for score in ['mean_test_recall','mean_test_precision']:
  plt.plot([_[1] for _ in df['param_class_weight']],
           df[score],
           label = score)
plt.legend();